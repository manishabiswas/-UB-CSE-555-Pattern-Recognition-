{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import svm, metrics\n",
    "\n",
    "def findAccuracy(predicted, actual):\n",
    "    \n",
    "    accuracy = 0.0\n",
    "    counter = 0 \n",
    "    for i in range (0,predicted.shape[0]):\n",
    "        if(predicted[i] == actual[i]):\n",
    "            counter+=1\n",
    "    accuracy = (counter*100)/predicted.shape[0]\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "t = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ Part 1 - Collect the Datasets ##########\n",
      "\n",
      "\n",
      "Reading the training data.\n",
      "\n",
      "Training Data read successfully.\n",
      "\n",
      "\n",
      "Reading the testing data.\n",
      "\n",
      "Testing Data read successfully.\n",
      "\n",
      "\n",
      "############ Part 1 Completed ##########\n"
     ]
    }
   ],
   "source": [
    "print(\"############ Part 1 - Collect the Datasets ##########\")\n",
    "print(\"\\n\\nReading the training data.\") \n",
    "stats_train = gzip.open('train-images-idx3-ubyte.gz', 'r')\n",
    "stats_train.read(16)\n",
    "img_dim = 28\n",
    "flat_size = img_dim*img_dim\n",
    "print(\"\\nTraining Data read successfully.\")\n",
    "n_img = 60000\n",
    "\n",
    "buf = stats_train.read(img_dim * img_dim * n_img)\n",
    "\n",
    "data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "x_train = data.reshape(n_img, img_dim * img_dim)\n",
    "\n",
    "stats_labels = gzip.open('train-labels-idx1-ubyte.gz','r')\n",
    "\n",
    "stats_labels.read(8)\n",
    "buf_labels = stats_labels.read(1 * 60000)\n",
    "y_train = np.frombuffer(buf_labels, dtype=np.uint8).astype(np.int64)\n",
    "\n",
    "print(\"\\n\\nReading the testing data.\")  \n",
    "stats_test = gzip.open('t10k-images-idx3-ubyte.gz', 'r')\n",
    "stats_test.read(16)\n",
    "n_img_test = 10000\n",
    "buf_test = stats_test.read(img_dim * img_dim * n_img_test)\n",
    "print(\"\\nTesting Data read successfully.\")\n",
    "\n",
    "data_test = np.frombuffer(buf_test, dtype=np.uint8).astype(np.float32)\n",
    "x_test = data_test.reshape(n_img_test, img_dim * img_dim)\n",
    "\n",
    "stats_test_labels = gzip.open('t10k-labels-idx1-ubyte.gz','r')\n",
    "\n",
    "stats_test_labels.read(8)\n",
    "buf_test_labels = stats_test_labels.read(1 * 10000)\n",
    "y_test = np.frombuffer(buf_test_labels, dtype=np.uint8).astype(np.int64)\n",
    "\n",
    "print(\"\\n\\n############ Part 1 Completed ##########\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ Part 2 - Developing the model classifier #################\n"
     ]
    }
   ],
   "source": [
    "print(\"############ Part 2 - Developing the model classifier #################\")\n",
    "\n",
    "# Initialize the SVC classifier\n",
    "classifier = svm.LinearSVC()\n",
    "\n",
    "\n",
    "## Train the classifier on training set\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "## Pefrorm prediction by the classifier\n",
    "pred_results = classifier.predict(x_test)\n",
    "\n",
    "print(\"\\n\\nTIME  = \", time.time() - t)\n",
    "\n",
    "accuracy = findAccuracy(pred_results, y_test)\n",
    "\n",
    "print(\"\\n\\nAccuracy = \", accuracy)\n",
    "\n",
    "print(\"############ Part 2 Completed ################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ Part 3 - Performing cross-validation and hyper-parameter tuning ###############\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"############ Part 3 - Performing cross-validation and hyper-parameter tuning ###############\")\n",
    "steps = [('scaler', StandardScaler()), ('SVM', SVC(kernel='poly'))]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "C_params = [0.001, 0.1, 0.5, 10, 100]\n",
    "gamma_params = [0.01, 0.1, 1, 5, 10]\n",
    "parameters = {'SVM__C':C_params, 'SVM__gamma':gamma_params}\n",
    "\n",
    "classifier = GridSearchCV(pipeline, param_grid=parameters, cv=5)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "print(\"\\n\\nTime taken for hyper-parameter tuning : \", time.time() - t)\n",
    "print (\"\\n\\nBest parameters found by GridSearchCV: \", classifier.best_params_)\n",
    "print(\"\\n\\nScore  = %3.5f\", classifier.score(x_test, y_test))\n",
    "\n",
    "\n",
    "accuracy = findAccuracy(y_pred, y_test)\n",
    "\n",
    "print(\"\\n\\nAccuracy calculated by self-defined function = \", accuracy)\n",
    "print(\"############ Part 3 - Completed ###############\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
